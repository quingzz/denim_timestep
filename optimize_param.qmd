---
title: "Optimize parameter"
toc: true
---

```{r warning=FALSE}
library(tidyverse)
library(denim)
```

## Overview

Due to being a discrete-time algorithm, denim output and performance depend on the time step used in the model. This dependency is summarized as followed:

-   Larger time steps lead to faster run time, but output tends to deviate from the corresponding continuous-time model

-   Smaller time step yield more "accurate" output but at the cost of slower run time.

This trade-off can be mitigated in 2 ways

-   **Adjust parameters**: adjust [parameters]{.underline} such that output using larger time step aligns with output from smaller one.

-   **Post-hoc adjustment**: adjust the [output]{.underline} to better align with smaller time step output.

## Set up

### Model structure

::: panel-tabset
## Model 1

```{r}
denim_mod <- denim_dsl({
  S -> I = beta*(I/N)*S
  I -> R = d_gamma(rate = ir_rate, shape = ir_shape)
  I -> D = d_weibull(scale = id_scale, shape = id_shape)
})

simulationDuration <- 40

initVals <- c(
  S = 990, I = 10, R = 0, D = 0
)

# ==== Parameters for denim =====
params <- list(
  N = 1000,
  ir_rate = 1/3, ir_shape = 3,
  id_scale = 10, id_shape = 1.5,
  beta = 0.4
)

# ==== Pars for helper ======
comps <- c("S", "I", "R", "D")

# ==== Pars for optim ======
# parameter and its lower + upper bound for model fitting task
par = c(
    beta = params$beta,
    ir_rate = params$ir_rate,
    ir_shape = params$ir_shape,
    id_scale = params$id_scale,
    id_shape = params$id_shape
  )
lower <- c(
  beta = params$beta - 0.2,
  ir_rate = params$ir_rate - 0.2,
  ir_shape = params$ir_shape - 2,
  id_scale = params$id_scale - 2,
  id_shape = params$id_shape - 2
)
upper <- c(
  beta = params$beta + 0.2,
  ir_rate = params$ir_rate + 0.2,
  ir_shape = params$ir_shape + 2,
  id_scale = params$id_scale + 2,
  id_shape = params$id_shape + 2
)
```

## Model 2

```{r}
denim_mod <- denim_dsl({
  S -> E = beta * S * (I/N) 
  E -> I = d_gamma(rate = ei_rate, shape = ei_shape)
  I -> R = d_gamma(rate = ir_rate, shape = ir_shape)
})

initVals <- c(S = 999999, E = 1, I= 0, R= 0)

simulationDuration <- 180

# ==== Parameters for denim =====
params <- list(
  beta = 0.58,
  N = 1e6, 
  ei_rate = 1/4, ei_shape = 2,
  ir_rate = 1/3, ir_shape = 2)

# ==== Pars for helper ======
comps <- c("S", "E", "I", "R")

# ==== Pars for optim ======
# parameter and its lower + upper bound for model fitting task
par = c(
    beta = params$beta,
    ei_rate = params$ei_rate,
    ei_shape = params$ei_shape,
    ir_rate = params$ir_rate,
    ir_shape = params$ir_shape
  )
lower <- c(
  beta = params$beta - 0.2,
  ei_rate = params$ei_rate - 0.2,
  ei_shape = params$ei_shape - 2,
  ir_rate = params$ir_rate - 0.2,
  ir_shape = params$ir_shape - 2
)
upper <- c(
  beta = params$beta + 0.2,
  ei_rate = params$ei_rate + 0.2,
  ei_shape = params$ei_shape + 2,
  ir_rate = params$ir_rate + 0.2,
  ir_shape = params$ir_shape + 2
)
```
:::

### Baseline

Use output at `timeStep = 0.01` as baseline

```{r}
# output when timeStep == 0.01
timeStep <- 0.01

baseline <- sim(denim_mod, 
    initialValues = initVals,
    parameters = params,
    timeStep = timeStep, 
    simulationDuration = simulationDuration)

# plot(baseline, ylim = c( 0, 1000))
```

### Helpers

```{r}
#| code-fold: true
#| code-summary: "helper functions"

# preprocess data 
preprocess_data <- function(baseline, out, 
                            comps = c("S", "I", "R", "D"), 
                             normalize = TRUE){
  baseline <- baseline %>% 
    pivot_longer(
      cols = comps,
      values_to = "pop",
      names_to = "comp"
    ) 
  out <- out %>% 
    pivot_longer(
      cols = comps,
      values_to = "pop",
      names_to = "comp"
    )
  
  out <- out %>% inner_join(
    baseline,
    by = join_by(Time == Time, comp == comp)
  )
  
  # print(head(out))
  
  if(normalize){
    out <- out %>% 
      group_by(Time) %>% 
      mutate(
        pop.x = pop.x/sum(pop.x),
        pop.y = pop.y/sum(pop.y)
      ) %>% 
      ungroup()
  }
  
  out
}

# helper for computing accuracy
# baseline is the output of baseline model (usually output when baseline = 0.001)
compute_accuracy <- function(data, error = "mae"){
  if(error!= "mae" & error != "mse"){
    stop("`error` must be either `mae` for Mean Absolute Error or `mse` for Mean Squared Error")
  }
  
  data %>% 
    mutate(
      diff = if(error == "mae"){abs(pop.y - pop.x)} else{(pop.y - pop.x)**2}
    ) %>% 
    summarize(
      mse = sum(diff, na.rm = TRUE)/n()
    ) %>% 
    pull(mse)
}

plot_compare <- function(data){
  data %>% 
    ggplot() +
      geom_point(
        aes(pop.x, pop.y),
        color = "cornflowerblue",
        shape = 20
      ) + 
      geom_line(
        aes(pop.x, pop.x),
        color = "red",
        linetype = "dashed"
      ) + 
      facet_wrap(~comp, scales="free") +
      labs(
        x = "Baseline",
        y = "Model"
      )
}

plot_output <- function(data){
  data %>% 
    ggplot() +
      geom_line(
        aes(x = Time, y = pop.x),
        color = "cornflowerblue"
      ) + 
      geom_line(
        aes(x = Time, y = pop.y),
        color = "red",
        linetype = "dashed"
      ) + 
      facet_wrap(~comp, scales="free") +
      labs(
        x = "Time",
        y = "Prop"
      )
}
```

## Adjust parameters

### Fit model

Try fitting model with `timeStep = 0.5` to output generated with `timeStep = 0.01`

```{r}
newTimeStep <- 0.5
```

```{r warning=FALSE}
#| code-fold: true
#| code-summary: "Code for fitting model"
target_function <- function(par){
  par <- as.list(par)
  new_params <- modifyList(params, par)
  
  out <- sim(
    denim_mod,
    initialValues = initVals,
    parameters = new_params,
    timeStep = newTimeStep,
    simulationDuration = simulationDuration
  )
  
  preprocess_data(baseline, out = out, comps = comps) %>% 
    compute_accuracy(error = "mse")
}

optim_out <- optim(
  par = par,
  target_function,
  method = "L-BFGS-B",
  lower = lower,
  upper = upper
)
```

Compare fitted parameters and parameters used to generate baseline (i.e. model with `timeStep = 0.01`)

```{r}
# fitted parameters
optim_out$par
# output parameters
params
```

### Compare output

::: panel-tabset
## Parameters from optim

```{r}
new_pars <- modifyList(params, as.list(optim_out$par))

out <- sim(denim_mod, 
  initialValues = initVals,
  parameters = new_pars,
  timeStep = newTimeStep, 
  simulationDuration = simulationDuration)

preprocess_data(baseline, out = out, comps = comps) %>% 
  plot_compare()

preprocess_data(baseline, out = out, comps = comps) %>% 
  plot_output()

preprocess_data(baseline, out = out, comps = comps) %>% 
  compute_accuracy()
```

## Old parameters

```{r}
out_oldparams <- sim(denim_mod, 
  initialValues = initVals,
  parameters = params,
  timeStep = newTimeStep, 
  simulationDuration = simulationDuration)

preprocess_data(baseline, out = out_oldparams, comps = comps) %>% 
  plot_compare()

preprocess_data(baseline, out = out_oldparams, comps = comps) %>% 
  plot_output()

preprocess_data(baseline, out = out_oldparams, comps = comps) %>% 
  compute_accuracy()
```
:::

### Discussion

It is possible to adjust parameters such that output using `timeStep = 0.5` can match output using `timeStep = 0.01`.

This means that depending on how `denim` is used, the issue of longer run time due to the need for smaller `timeStep` may be trivial.

Denim use cases could be categorized into 2 groups:

-   **Model fitting:** If the task at hand is to fit the model to a dataset, it is better to use larger `timeStep` where run time is fast enough, but still small enough for a smooth output + convergence. Just be aware that the fitted parameters may varies slightly depending on the `timeStep` used.

-   **Simulation:** If users need to simulate a model with a set of parameters derived from a continuous time estimates, it is better to use small `timeStep` (where issue of longer run time persists).

## Adjust output

### Correlation between error and timeStep

Plotting MAE shows that the divergence in output does linearly correlates with grow in `timeStep` but only within smaller range of `timeStep` (typically `[0-1]`) but gets unpredictable as `timeStep` becomes larger than that range

```{r}
#| code-fold: true
#| code-summary: "Code for compute MSE at different timeStep"
dt_acc <- data.frame(
    dt = seq(0.05, 5, 0.05)
  ) %>% 
  mutate(
    mae = map_dbl(dt, \(curr_dt){
      
      curr_out <- sim(
        denim_mod,
        initialValues = initVals,
        parameters = params,
        simulationDuration = simulationDuration,
        timeStep = curr_dt
      )
      
      preprocess_data(baseline, out = curr_out, comps = comps) %>% 
        compute_accuracy()
    })
  )

dt_acc %>% 
  ggplot(
    aes(
      x = dt, y = mae
    )
  ) +
  geom_point(color = "cornflowerblue", shape = 20) +
  labs(
    title = "Correlation between timeStep and error",
    x = "timeStep",
    y = "Mean Absolute Error"
  )

# ggsave("figures/dt_error.png", width = 8, height = 5, dpi = 300)
```

### Change in output

Visualize difference between output using `timeStep = 0.01` and `timeStep = 0.5` using the same set of parameters

```{r}
#| code-fold: true
#| code-summary: "Code for plotting"
preprocess_data(baseline, out_oldparams, comps = comps) %>% 
  mutate(
    diff = pop.y - pop.x
  ) %>% 
  ggplot() +
    geom_line(
      aes(x = Time, y = diff),
      color = "red"
    ) +
    geom_hline(
      yintercept = 0,
      linetype = "dashed"
    ) +
    facet_wrap(~ comp) +
    labs(
      title = "Difference between baseline and output",
      x = "(Simulation) Time",
      y = "Baseline - Output"
    )

# ggsave("figures/visualize_incorrectness.png", width = 8, height = 5, dpi = 300)
```
