---
title: "Optimize parameter"
---

```{r}
library(tidyverse)
library(denim)
```

## Overview

Due to being a discrete-time algorithm, denim output and performance depends on the time step used for the model. Said dependence is summarized as followed:

-   The larger time step used, the algorithm [runs faster]{.underline} but will [diverge from continuous time model output]{.underline}.

-   The smaller time step used, the algorithm [runs slower]{.underline} but [output will closely follow that of a continuous time model]{.underline}.

There are 2 approaches to mitigate this trade-offs

-   **Adjust parameters**: adjust parameters such that output using 1 time step match that from other smaller time step

    -   If this is possible: for model fitting task, isn't it better to just use a larger time step (e.g. 0.5)? (since it will converge anyways, just with slightly different parameters compared to fitted parameters with finer timeSteps)

-   **Post-hoc adjustment**: adjust the output from 1 timeStep to match that from other timeStep

    -   Can we meta-model the change in output as timeStep change? If possible, can said meta-model applied to different denim model structure?

## Set up

### Model structure

Model 1

```{r}
denim_mod <- denim_dsl({
  S -> I = beta*(I/N)*S
  I -> R = d_gamma(rate = ir_rate, shape = ir_shape)
  I -> D = d_weibull(scale = id_scale, shape = id_shape)
})

simulationDuration <- 40

initVals <- c(
  S = 990, I = 10, R = 0, D = 0
)

# ==== Parameters for denim =====
params <- list(
  N = 1000,
  ir_rate = 1/3, ir_shape = 3,
  id_scale = 10, id_shape = 1.5,
  beta = 0.4
)

# ==== Pars for helper ======
comps <- c("S", "I", "R", "D")

# ==== Pars for optim ======
# parameter and its lower + upper bound for model fitting task
par = c(
    beta = params$beta,
    ir_rate = params$ir_rate,
    ir_shape = params$ir_shape,
    id_scale = params$id_scale,
    id_shape = params$id_shape
  )
lower <- c(
  beta = params$beta - 0.2,
  ir_rate = params$ir_rate - 0.2,
  ir_shape = params$ir_shape - 2,
  id_scale = params$id_scale - 2,
  id_shape = params$id_shape - 2
)
upper <- c(
  beta = params$beta + 0.2,
  ir_rate = params$ir_rate + 0.2,
  ir_shape = params$ir_shape + 2,
  id_scale = params$id_scale + 2,
  id_shape = params$id_shape + 2
)
```

Model 2

```{r}
denim_mod <- denim_dsl({
  S -> E = beta * S * (I/N) 
  E -> I = d_gamma(rate = ei_rate, shape = ei_shape)
  I -> R = d_gamma(rate = ir_rate, shape = ir_shape)
})

initVals <- c(S = 999999, E = 1, I= 0, R= 0)

simulationDuration <- 180

# ==== Parameters for denim =====
params <- list(
  beta = 0.58,
  N = 1e6, 
  ei_rate = 1/4, ei_shape = 2,
  ir_rate = 1/3, ir_shape = 2)

# ==== Pars for helper ======
comps <- c("S", "E", "I", "R")

# ==== Pars for optim ======
# parameter and its lower + upper bound for model fitting task
par = c(
    beta = params$beta,
    ei_rate = params$ei_rate,
    ei_shape = params$ei_shape,
    ir_rate = params$ir_rate,
    ir_shape = params$ir_shape
  )
lower <- c(
  beta = params$beta - 0.2,
  ei_rate = params$ei_rate - 0.2,
  ei_shape = params$ei_shape - 2,
  ir_rate = params$ir_rate - 0.2,
  ir_shape = params$ir_shape - 2
)
upper <- c(
  beta = params$beta + 0.2,
  ei_rate = params$ei_rate + 0.2,
  ei_shape = params$ei_shape + 2,
  ir_rate = params$ir_rate + 0.2,
  ir_shape = params$ir_shape + 2
)
```

### Baseline

Use output at `timeStep = 0.01` as baseline

```{r}
# output when timeStep == 0.01
timeStep <- 0.01

baseline <- sim(denim_mod, 
    initialValues = initVals,
    parameters = params,
    timeStep = timeStep, 
    simulationDuration = simulationDuration)

plot(baseline, ylim = c( 0, 1e6))
```

### Helpers

```{r}
# preprocess data 
preprocess_data <- function(baseline, out, 
                            comps = c("S", "I", "R", "D"), 
                             normalize = TRUE){
  baseline <- baseline %>% 
    pivot_longer(
      cols = comps,
      values_to = "pop",
      names_to = "comp"
    ) 
  out <- out %>% 
    pivot_longer(
      cols = comps,
      values_to = "pop",
      names_to = "comp"
    )
  
  out <- out %>% inner_join(
    baseline,
    by = join_by(Time == Time, comp == comp)
  )
  
  # print(head(out))
  
  if(normalize){
    out <- out %>% 
      group_by(Time) %>% 
      mutate(
        pop.x = pop.x/sum(pop.x),
        pop.y = pop.y/sum(pop.y)
      ) %>% 
      ungroup()
  }
  
  out
}

# helper for computing accuracy
# baseline is the output of baseline model (usually output when baseline = 0.001)
compute_accuracy <- function(data){
  data %>% 
    mutate(
      diff = (pop.y - pop.x)**2
    ) %>% 
    summarize(
      mse = sum(diff, na.rm = TRUE)/n()
    ) %>% 
    pull(mse)
}

plot_compare <- function(data){
  data %>% 
    ggplot() +
      geom_point(
        aes(pop.x, pop.y),
        color = "cornflowerblue",
        shape = 20
      ) + 
      geom_line(
        aes(pop.x, pop.x),
        color = "red",
        linetype = "dashed"
      ) + 
      facet_wrap(~comp, scales="free") +
      labs(
        x = "Baseline",
        y = "Model"
      )
}

plot_output <- function(data){
  data %>% 
    ggplot() +
      geom_line(
        aes(x = Time, y = pop.x),
        color = "cornflowerblue"
      ) + 
      geom_line(
        aes(x = Time, y = pop.y),
        color = "red",
        linetype = "dashed"
      ) + 
      facet_wrap(~comp, scales="free") +
      labs(
        x = "Time",
        y = "Prop"
      )
}
```

## Adjust parameters

### Fit model

```{r}
newTimeStep <- 0.5
```

```{r}
target_function <- function(par){
  par <- as.list(par)
  new_params <- modifyList(params, par)
  
  out <- sim(
    denim_mod,
    initialValues = initVals,
    parameters = new_params,
    timeStep = newTimeStep,
    simulationDuration = simulationDuration
  )
  
  preprocess_data(baseline, out = out, comps = comps) %>% 
    compute_accuracy()
}

optim_out <- optim(
  par = par,
  target_function,
  method = "L-BFGS-B",
  lower = lower,
  upper = upper
)
```

```{r}
# fitted parameters
optim_out$par
# output parameters
params
```

### Compare output

#### Parameters from optim

```{r}
new_pars <- modifyList(params, as.list(optim_out$par))

out <- sim(denim_mod, 
  initialValues = initVals,
  parameters = new_pars,
  timeStep = newTimeStep, 
  simulationDuration = simulationDuration)

preprocess_data(baseline, out = out, comps = comps) %>% 
  plot_compare()

preprocess_data(baseline, out = out, comps = comps) %>% 
  plot_output()

preprocess_data(baseline, out = out, comps = comps) %>% 
  compute_accuracy()
```

#### Same parameters

```{r}
out <- sim(denim_mod, 
  initialValues = initVals,
  parameters = params,
  timeStep = newTimeStep, 
  simulationDuration = simulationDuration)

preprocess_data(baseline, out = out, comps = comps) %>% 
  plot_compare()

preprocess_data(baseline, out = out, comps = comps) %>% 
  plot_output()

preprocess_data(baseline, out = out, comps = comps) %>% 
  compute_accuracy()
```

### Discussion

It is possible to adjust parameters such that output using `timeStep = 0.5` can match output using `timeStep = 0.01`.

This means that depending on how `denim` is used, the issue of longer run time due to the need for smaller `timeStep` may be trivial.

Denim use cases could be categorized into 2 groups:

-   **Model fitting:** If the task at hand is to fit the model to a dataset, it is better to use larger `timeStep` where run time is fast enough, but still small enough for a smooth output + convergence. Just be aware that the fitted parameters may varies slightly depending on the `timeStep` used.

-   **Simulation:** If users need to simulate a model with a set of parameters derived from a continuous time estimates, it is better to use small `timeStep` where issue of longer run time persists.

## Adjust output

TBD: More literature on

-   conversion between discrete-time and continuous-time system

-   similarity transformation (?)
